# Pré-processamento de Dados para Machine Learning

## Exemplo 1: Codificação de Variáveis Categóricas
```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Criando dados categóricos
dados = pd.DataFrame({
    'categoria': ['A', 'B', 'C', 'A', 'B'],
    'tipo': ['X', 'Y', 'X', 'Y', 'X']
})

# Label Encoding
label_encoder = LabelEncoder()
dados['categoria_encoded'] = label_encoder.fit_transform(dados['categoria'])

# One-Hot Encoding
one_hot = pd.get_dummies(dados[['tipo']], prefix='tipo')
dados = pd.concat([dados, one_hot], axis=1)
```

## Exemplo 2: Seleção de Features
```python
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.datasets import make_classification

# Criando dados de exemplo
X, y = make_classification(n_samples=100, n_features=20, n_informative=5)

# Selecionando as 5 melhores features
selector = SelectKBest(score_func=f_classif, k=5)
X_selected = selector.fit_transform(X, y)

# Obtendo os índices das features selecionadas
selected_features = selector.get_support(indices=True)
```

## Exemplo 3: Redução de Dimensionalidade
```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Criando dados de exemplo
X = np.random.randn(100, 10)

# Padronizando os dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Aplicando PCA
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X_scaled)

# Verificando variância explicada
print(f"Variância explicada: {pca.explained_variance_ratio_}")
```

## Dicas importantes:
1. Escolha o método de codificação adequado
2. Normalize os dados antes de aplicar PCA
3. Considere a importância das features
4. Mantenha os transformadores para dados novos 