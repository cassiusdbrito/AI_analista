

thank you so much for your code. It worked for me. If you look at the first line where it says conn.recv (386000), what goes in the parenthesis is how many bytes you will permit your server to receive at a time. I calculated that the size of each frame will be 640 * 480 (The resolution of your video), which when multiplied gives about 307,200 pixels. I just increased the amount of bytes my server is allowed to receive, I gave it a bit of room as I noticed that the size of the images do vary which was why I set it to 386,000. essentially just keep increasing the amount of the bytes your server can receive and eventually, it will permit you to stream your images. The amount of bytes you need to be able to receive will be around the resolution of your video plus an additional 100,000 bytes, just play around with these number. so if your footage is 1080*1920, you'd probably want to set your conn.recv(2073600), which is 1080 multiplied by 1920. you will probably need to add an addition 100,000 to 200,000 bytes as an allowance. again just play around with the numbers.

while True:
    data = conn.recv(386000)
    nparr = numpy.frombuffer(data, numpy.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    #print(numpy.shape(img))
    cv2.imshow('VideoCap', img)
    
    if cv2.waitKey(1) == ord('q'):
        break
    
    if not data:
        break

cv2.destroyAllWindows()    
conn.close()









Share


Improve this answer



                        Follow
                        










edited Mar 25 at 12:53














            answered Mar 11 at 12:51






OmoOmo

111 bronze badge






